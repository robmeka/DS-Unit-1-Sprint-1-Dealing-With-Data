{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LS_DS_113_Making_Data_backed_Assertions_Assignment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robmeka/DS-Unit-1-Sprint-1-Dealing-With-Data/blob/master/module3-databackedassertions/LS_DS_113_Making_Data_backed_Assertions_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Okfr_uhwhS1X",
        "colab_type": "text"
      },
      "source": [
        "# Lambda School Data Science - Making Data-backed Assertions\n",
        "\n",
        "This is, for many, the main point of data science - to create and support reasoned arguments based on evidence. It's not a topic to master in a day, but it is worth some focused time thinking about and structuring your approach to it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOqaPds9huME",
        "colab_type": "text"
      },
      "source": [
        "## Assignment - what's going on here?\n",
        "\n",
        "Consider the data in `persons.csv` (already prepared for you, in the repo for the week). It has four columns - a unique id, followed by age (in years), weight (in lbs), and exercise time (in minutes/week) of 1200 (hypothetical) people.\n",
        "\n",
        "Try to figure out which variables are possibly related to each other, and which may be confounding relationships.\n",
        "\n",
        "Try and isolate the main relationships and then communicate them using crosstabs and graphs. Share any cool graphs that you make with the rest of the class in Slack!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGUS79cOhPWj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "82ee8fa2-4dc8-485b-fe20-79570ae8b6f8"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.reader_csv(https://raw.githubusercontent.com/robmeka/DS-Unit-1-Sprint-1-Dealing-With-Data/master/module3-databackedassertions/persons.csv\n",
        "print df.shape\n",
        "df.head()                 \n",
        "\n",
        "                 \n",
        "import pandas as pd\n",
        "exercise_time=pd.dataframe(weight)\n",
        "exercise_data.weight()                 "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-83fbdee5e6f3>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    df=pd.reader_csv(https://raw.githubusercontent.com/robmeka/DS-Unit-1-Sprint-1-Dealing-With-Data/master/module3-databackedassertions/persons.csv\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JneOV89pSf2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "5011d085-9155-45a3-8f9a-55d167bde3b7"
      },
      "source": [
        "import pandas as pd\n",
        "exercise_time=pd.dataframe(weight)\n",
        "exercise_data.weight()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-61dbe157ce83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexercise_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mexercise_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'dataframe'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnY7d7NGSyR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "09893c68-79b0-44e1-e058-bcbdcab85195"
      },
      "source": [
        "pd.crosstab(user_data['exercise'])\n",
        "user_data[minutes]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-84baf495f400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exercise'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0muser_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mminutes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'user_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT9gdS7viJZa",
        "colab_type": "text"
      },
      "source": [
        "### Assignment questions\n",
        "\n",
        "After you've worked on some code, answer the following questions in this text block:\n",
        "\n",
        "1.  What are the variable types in the data? exercise and weight\n",
        "2.  What are the relationships between the variables?The weight goes down with more exercise\n",
        "3.  Which relationships are \"real\", and which spurious? Age is real\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XXg2crAipwP",
        "colab_type": "text"
      },
      "source": [
        "## Stretch goals and resources\n",
        "\n",
        "Following are *optional* things for you to take a look at. Focus on the above assignment first, and make sure to commit and push your changes to GitHub.\n",
        "\n",
        "- [Spurious Correlations](http://tylervigen.com/spurious-correlations)\n",
        "- [NIH on controlling for confounding variables](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4017459/)\n",
        "\n",
        "Stretch goals:\n",
        "\n",
        "- Produce your own plot inspired by the Spurious Correlation visualizations (and consider writing a blog post about it - both the content and how you made it)\n",
        "- Pick one of the techniques that NIH highlights for confounding variables - we'll be going into many of them later, but see if you can find which Python modules may help (hint - check scikit-learn)"
      ]
    }
  ]
}